{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze NetBERT improvements over BERT predictions\n",
    "The goal is to extract the right predictions of BERT-base on the dev set, and pass only these subset to NetBERT to see if it performs at least as well as BERT-base. Then, extract the wrong predictions of BERT-base and see where NetBERT improves, which specific cases, which classes in particluar, which type of sentences (badly written, not clear?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare eval datasets from bert-base predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eval_dataset(infile, outfile, class_mappings):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Load right predictions from BERT-base\n",
    "    df = pd.read_csv(os.path.join(dirpath, infile), index_col=0)\n",
    "\n",
    "    # Create columns with classes.\n",
    "    df['Class'] = df.apply(lambda row: class_mappings[str(row.Class_id)], axis=1)\n",
    "    df['Prediction'] = df.apply(lambda row: class_mappings[str(row.Prediction_id)], axis=1)\n",
    "\n",
    "    # Drop useless columns.\n",
    "    to_drop = ['Class_id', 'Prediction_id', 'Prediction']\n",
    "    df.drop(to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    # Save dataset for evaluation with NetBERT.\n",
    "    df.to_csv(os.path.join(dirpath, outfile))\n",
    "    return df\n",
    "\n",
    "\n",
    "# Load class-class_id mapping.\n",
    "dirpath = '/raid/antoloui/Master-thesis/Code/Extrinsic_evaluation/Classification/output/bert_base_cased/'\n",
    "with open(os.path.join(dirpath, 'map_classes.json')) as f:\n",
    "    class_mappings = json.load(f)\n",
    "\n",
    "# Create eval dataset from BERT-base right predictions.\n",
    "df_bert_right = create_eval_dataset(infile='preds_right.csv', outfile='eval_right_preds.csv', class_mappings=class_mappings)\n",
    "\n",
    "# Create eval dataset from BERT-base wrong predictions.\n",
    "df_bert_wrong = create_eval_dataset(infile='preds_wrong.csv', outfile='eval_wrong_preds.csv', class_mappings=class_mappings)\n",
    "\n",
    "# Create full test dataset.\n",
    "df_bert = pd.concat([df_bert_right,df_bert_wrong], ignore_index=True)\n",
    "df_bert.to_csv(os.path.join(dirpath, 'eval_preds.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze predictions of NetBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. On queries correclty classified by BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. On queries wrongly classified by BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NetBERT predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = '/raid/antoloui/Master-thesis/Code/Extrinsic_evaluation/Classification/output/netbert-1880000/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On BERT right predictions only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load right predictions from BERT-base\n",
    "df_bert_right = pd.read_csv(os.path.join(dirpath, 'preds_right.csv'), index_col=0)\n",
    "\n",
    "# Create columns with classes.\n",
    "df_bert_right['Class'] = df_bert_right.apply(lambda row: class_mappings[str(row.Class_id)], axis=1)\n",
    "df_bert_right['Prediction'] = df_bert_right.apply(lambda row: class_mappings[str(row.Prediction_id)], axis=1)\n",
    "\n",
    "# Save dataset for evaluation with NetBERT.\n",
    "to_drop = ['Class_id', 'Prediction_id', 'Prediction']\n",
    "df_bert_right.drop(to_drop, axis=1, inplace=True)\n",
    "df_bert_right.to_csv(os.path.join(dirpath, 'eval_right_preds.csv'))\n",
    "df_bert_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9631979695431472,\n",
       " 'Precision': 0.9616735588794019,\n",
       " 'Recall': 0.9619604922685113,\n",
       " 'F1 score': 0.961536700021114,\n",
       " 'MCC': 0.9540423108263494,\n",
       " 'conf_matrix': [[0.9403973509933775,\n",
       "   0.033112582781456956,\n",
       "   0.026490066225165563,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  [0.021739130434782608,\n",
       "   0.9565217391304348,\n",
       "   0.0,\n",
       "   0.014492753623188406,\n",
       "   0.007246376811594203],\n",
       "  [0.0, 0.046052631578947366, 0.9473684210526315, 0.0, 0.006578947368421052],\n",
       "  [0.0, 0.017142857142857144, 0.0, 0.9771428571428571, 0.005714285714285714],\n",
       "  [0.0, 0.0, 0.011627906976744186, 0.0, 0.9883720930232558]]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, classes):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    cm = np.array(cm)\n",
    "    df_cm = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "    \n",
    "    plt.figure(figsize = (10,7))\n",
    "    ax = sn.heatmap(df_cm, annot=True)\n",
    "    \n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=8, horizontalalignment='right', rotation=45) \n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=8)\n",
    "    \n",
    "    plt.title('Confusion matrix', fontsize=18)\n",
    "    plt.ylabel('True labels', fontsize=12)\n",
    "    plt.xlabel('Predicted labels', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    #plt.savefig(outdir+\"confusion_matrix.png\")\n",
    "    #plt.close()\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "# Load results.\n",
    "with open(os.path.join(dirpath, 'scores_bert_right_preds.json')) as f:\n",
    "    result = json.load(f)\n",
    "    \n",
    "# Accuracy\n",
    "print(\"Accuracy: {}\".format(result['Accuracy']))\n",
    "\n",
    "# Confusion matrix\n",
    "plot_confusion_matrix(result['conf_matrix'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
