{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check full size of original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antoloui/anaconda3/envs/data/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f916c35f18466a857b2e699168b548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from 11699 documents in file '1.json'...\n",
      "Extracting text from 32072 documents in file '2.json'...\n",
      "Extracting text from 8225 documents in file '3.json'...\n",
      "Extracting text from 77258 documents in file '4.json'...\n",
      "Extracting text from 46079 documents in file '5.json'...\n",
      "Extracting text from 28106 documents in file '6.json'...\n",
      "Extracting text from 27391 documents in file '7.json'...\n",
      "Extracting text from 24143 documents in file '8.json'...\n",
      "Extracting text from 22223 documents in file '9.json'...\n",
      "Extracting text from 20979 documents in file '10.json'...\n",
      "Extracting text from 57160 documents in file '11.json'...\n",
      "Extracting text from 85900 documents in file '12.json'...\n",
      "Extracting text from 793 documents in file '13.json'...\n",
      "\n",
      "Creating dataframe...\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for id_file in tqdm(range(1,14)):\n",
    "    file_path = \"../../Data/Original_data/\" + str(id_file) + \".json\"\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        data = json.load(f)  # data is a list of dict of the form: {'text':['...'], 'uri':['...']}\n",
    "\n",
    "        print(\"Extracting text from {} documents in file '{}.json'...\".format(len(data), id_file))\n",
    "        for i, doc in enumerate(data):\n",
    "            text = doc.get('text') # Get the text of the current doc\n",
    "            if text is not None:\n",
    "                text = ' '.join(doc.get('text')) # Flatten list of strings\n",
    "                row_dict = {'Text': text, 'Length': len(text)}\n",
    "                rows.append(row_dict)\n",
    "\n",
    "print(\"Creating dataframe...\")\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"Done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving sentences to output file...\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving sentences to output file...\")\n",
    "sentences = \"\\n\\n\".join(df[\"Text\"])\n",
    "with open(\"../../Data/Original/raw_text.txt\", \"w+\") as f:\n",
    "    f.write(sentences)\n",
    "print(\"Done !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of all raw text without preprocessing is 19Gb !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 antoloui antoloui 19G Jan 30 16:15 /home/antoloui/Master-thesis/Data/raw_text.txt\n"
     ]
    }
   ],
   "source": [
    "! ls -lh /home/antoloui/Master-thesis/Data/raw_text.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of '.ipynb_checkpoints': 0.0000 GB\n",
      "Size of 'First_try': 0.0000 GB\n",
      "Size of 'test': 0.0000 GB\n",
      "Size of 'tf_examples.tfrecord1': 17.1765 GB\n",
      "Size of 'tf_examples.tfrecord10': 8.8751 GB\n",
      "Size of 'tf_examples.tfrecord11': 21.5082 GB\n",
      "Size of 'tf_examples.tfrecord12': 30.1326 GB\n",
      "Size of 'tf_examples.tfrecord13': 0.0083 GB\n",
      "Size of 'tf_examples.tfrecord2': 1.2934 GB\n",
      "Size of 'tf_examples.tfrecord3': 3.4834 GB\n",
      "Size of 'tf_examples.tfrecord4': 29.4735 GB\n",
      "Size of 'tf_examples.tfrecord5': 10.7820 GB\n",
      "Size of 'tf_examples.tfrecord6': 9.7201 GB\n",
      "Size of 'tf_examples.tfrecord7': 8.5420 GB\n",
      "Size of 'tf_examples.tfrecord8': 10.5401 GB\n",
      "Size of 'tf_examples.tfrecord9': 7.1263 GB\n",
      "Total size: 158.6615 GB\n"
     ]
    }
   ],
   "source": [
    "directory = '/raid/antoloui/Master-thesis/Data/bert/'\n",
    "files = os.listdir(directory).sort()\n",
    "total_size = 0\n",
    "for filename in sorted(os.listdir(directory)):\n",
    "    file_path = directory + filename\n",
    "    size = os.path.getsize(file_path)/(1024*1024*1024)\n",
    "    total_size += size\n",
    "    print(\"Size of '{}': {:.4f} GB\".format(filename, size))\n",
    "print(\"Total size: {:.4f} GB\".format(total_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of 'bert_config.json': 0.0000 GB\n",
      "Size of 'bert_model.ckpt.data-00000-of-00001': 0.4058 GB\n",
      "Size of 'bert_model.ckpt.index': 0.0000 GB\n",
      "Size of 'bert_model.ckpt.meta': 0.0008 GB\n",
      "Size of 'vocab.txt': 0.0002 GB\n",
      "Total size: 0.4069 GB\n"
     ]
    }
   ],
   "source": [
    "directory = '/raid/antoloui/Master-thesis/Code/bert_singleGPU/models/base_cased/'\n",
    "files = os.listdir(directory).sort()\n",
    "total_size = 0\n",
    "for filename in sorted(os.listdir(directory)):\n",
    "    file_path = directory + filename\n",
    "    size = os.path.getsize(file_path)/(1024*1024*1024)\n",
    "    total_size += size\n",
    "    print(\"Size of '{}': {:.4f} GB\".format(filename, size))\n",
    "print(\"Total size: {:.4f} GB\".format(total_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sample_path = '/raid/antoloui/Master-thesis/Data/Cleaned/dev.json'\n",
    "with open(sample_path) as infile:\n",
    "    for i, line in enumerate(infile):\n",
    "        if i==19:\n",
    "            doc = json.loads(line)\n",
    "            with open('sample.txt', 'w+') as outfile:\n",
    "                outfile.write(doc.get('text'))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
