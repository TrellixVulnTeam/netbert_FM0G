{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Data extraction\n",
    "\n",
    "Extract text contained in json files and save it in a dataframe for further pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'cudf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-0e231441128b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'cudf'"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import json\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import cudf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db53ffe3eca4619ae5f789717319b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1 - Keys: {'text', 'uri'} - Documents: 11699\n",
      "File 2 - Keys: {'text', 'uri'} - Documents: 32072\n",
      "File 3 - Keys: {'text', 'uri'} - Documents: 8225\n",
      "File 4 - Keys: {'text', 'uri'} - Documents: 77258\n",
      "File 5 - Keys: {'text', 'uri'} - Documents: 46079\n",
      "File 6 - Keys: {'text', 'uri'} - Documents: 28106\n",
      "File 7 - Keys: {'text', 'uri'} - Documents: 27391\n",
      "File 8 - Keys: {'text', 'uri'} - Documents: 24143\n",
      "File 9 - Keys: {'text', 'uri'} - Documents: 22223\n",
      "File 10 - Keys: {'text', 'uri'} - Documents: 20979\n",
      "File 11 - Keys: {'text', 'uri'} - Documents: 57160\n",
      "File 12 - Keys: {'text', 'uri'} - Documents: 85900\n",
      "File 13 - Keys: {'text', 'uri'} - Documents: 793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the different keys in the json file\n",
    "for id_file in tqdm(range(1,14)):\n",
    "    file_path = \"./../Data/Original_data/\" + str(id_file) + \".json\"\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        # Loop over each document\n",
    "        keys = []\n",
    "        for i, doc in enumerate(data):\n",
    "            for key, value in doc.items():\n",
    "                keys.append(key)\n",
    "\n",
    "        myset = set(keys)\n",
    "        print(\"File {} - Keys: {} - Documents: {}\".format(id_file, myset, len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aea337d66734a9099de3c58117073f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file 1...\n",
      "Extracting text from 11699 documents in file...\n",
      "Loading file 2...\n",
      "Extracting text from 32072 documents in file...\n",
      "Loading file 3...\n",
      "Extracting text from 8225 documents in file...\n",
      "Loading file 4...\n",
      "Extracting text from 77258 documents in file...\n",
      "Loading file 5...\n",
      "Extracting text from 46079 documents in file...\n",
      "Loading file 6...\n",
      "Extracting text from 28106 documents in file...\n",
      "Loading file 7...\n",
      "Extracting text from 27391 documents in file...\n",
      "Loading file 8...\n",
      "Extracting text from 24143 documents in file...\n",
      "Loading file 9...\n",
      "Extracting text from 22223 documents in file...\n",
      "Loading file 10...\n",
      "Extracting text from 20979 documents in file...\n",
      "Loading file 11...\n",
      "Extracting text from 57160 documents in file...\n",
      "Loading file 12...\n",
      "Extracting text from 85900 documents in file...\n",
      "Loading file 13...\n",
      "Extracting text from 793 documents in file...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Americas Headquarters: Cisco Systems, Inc., 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For the latest version of the Cisco Small Busi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WebEx Meeting Center User Guide  For Hosts, Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78-4019959-01 Rev D  Prisma II 1550 nm SuperQA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Release Notes for Cisco RV130/RV130W Firmware ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442014</th>\n",
       "      <td>Cisco Unified Communications System for IP Tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442015</th>\n",
       "      <td>Cisco Unified Communications System for IP Tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442016</th>\n",
       "      <td>Cisco Unified Communications System for IP Tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442017</th>\n",
       "      <td>Cisco Unified Communications System for IP Tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442018</th>\n",
       "      <td>Cisco Unified Communications System for IP Tel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442019 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text\n",
       "0       Americas Headquarters: Cisco Systems, Inc., 17...\n",
       "1       For the latest version of the Cisco Small Busi...\n",
       "2       WebEx Meeting Center User Guide  For Hosts, Pr...\n",
       "3       78-4019959-01 Rev D  Prisma II 1550 nm SuperQA...\n",
       "4       Release Notes for Cisco RV130/RV130W Firmware ...\n",
       "...                                                   ...\n",
       "442014  Cisco Unified Communications System for IP Tel...\n",
       "442015  Cisco Unified Communications System for IP Tel...\n",
       "442016  Cisco Unified Communications System for IP Tel...\n",
       "442017  Cisco Unified Communications System for IP Tel...\n",
       "442018  Cisco Unified Communications System for IP Tel...\n",
       "\n",
       "[442019 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for id_file in tqdm(range(1, 14)):\n",
    "    file_path = \"./../Data/Original_data/\" + str(id_file) + \".json\"\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        print(\"Loading file {}...\".format(id_file))\n",
    "        data = json.load(f)  # data is a list of dict of the form: {'text':['...'], 'uri':['...']}\n",
    "\n",
    "        print(\"Extracting text from {} documents in file...\".format(len(data), id_file))\n",
    "        for i, doc in enumerate(data):\n",
    "            text = doc.get('text') # Get the text of the current doc\n",
    "            if text is not None:\n",
    "                row_dict = {'Text': text[0]}\n",
    "                rows.append(row_dict)\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Data Processing\n",
    "\n",
    "In order to use \"create_pretraining_data.py\" from BERT repository, the input must be a plain text file, with one sentence per line and one blank line between documents:\n",
    "\n",
    "  * One sentence per line. These should ideally be actual sentences, not entire paragraphs or arbitrary spans of text. (Because we use the sentence boundaries for the \"next sentence prediction\" task).\n",
    "  * Blank lines between documents. Document boundaries are needed so that the \"next sentence prediction\" task doesn't span between documents.\n",
    "  \n",
    "They advise to perform sentence segmentation with an off-the-shelf NLP toolkit such as spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample df for testing\n",
    "sample_df = df.copy(deep=True)\n",
    "sample_df = sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Corpus Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.Text = sample_df.Text.replace('\\s+', ' ', regex=True)  # Remove duplicate spaces\n",
    "sample_df.Text = sample_df.Text.str.encode('ascii', 'ignore').str.decode('utf-8')   # Encode in ascii to remove weird characters such as \\uf0a7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence segmentation with spacy\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def sent_segmentation(doc_text):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    doc = nlp(doc_text)\n",
    "    sentences = list(doc.sents)\n",
    "    sentences = [sent.text for sent in sentences]\n",
    "    sentences = \"\\n\".join(sentences)\n",
    "    return sentences\n",
    "\n",
    "sentences = sent_segmentation(sample)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Sentence Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If line begins with a number, remove the number\n",
    "\n",
    "# If line has more than 10 punctuations, remove line\n",
    "\n",
    "# If line has only 2 words, remove it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
