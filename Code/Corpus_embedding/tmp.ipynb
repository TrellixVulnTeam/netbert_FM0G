{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import logging\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentences(filepath):\n",
    "    \"\"\"\n",
    "    Given a file of raw sentences, return the list of these sentences.\n",
    "    \"\"\"\n",
    "    # Load sentences from file.\n",
    "    with open(filepath) as myfile:\n",
    "        sentences = [line for line in myfile if line != '\\n']\n",
    "    \n",
    "    # Only keep unique sentences.\n",
    "    sentences = list(dict.fromkeys(sentences).keys())\n",
    "    \n",
    "    # Only keep sentences with less than 1300 char (bigger sentences are messed up).\n",
    "    sentences = [sent for sent in sentences if len(sent) <= 1300]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def tokenize(tokenizer, sentences):\n",
    "    \"\"\"\n",
    "    Given a list of sentences, convert words to vocab ids (0 -> 30522) in each sentence.\n",
    "    \"\"\"\n",
    "    logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)  # No warning on sample size (I deal with that below).\n",
    "    indexed_tokens = [tokenizer.encode(sent, add_special_tokens=True) for sent in sentences]    \n",
    "    return indexed_tokens\n",
    "\n",
    "\n",
    "def create_chunks(sentences, indexed_tokens):\n",
    "    \"\"\"\n",
    "    Given the tokenized sentences, return chunks of multiple sentences under 512 tokens.\n",
    "    \"\"\"\n",
    "    token_chunks = [] \n",
    "    sentence_chunks = []\n",
    "\n",
    "    # While list of tokenized sentences is not empty...\n",
    "    while indexed_tokens:\n",
    "\n",
    "        # Create the new chunk.\n",
    "        chunk_tok = []\n",
    "        chunk_sent = []\n",
    "\n",
    "        # If:\n",
    "        #  - The current chunk is empty;\n",
    "        #  - There is still sentences to pop in the list;\n",
    "        #  - The next sentence to pop is bigger than 512 tokens;\n",
    "        if (not chunk_tok) and (indexed_tokens) and (len(indexed_tokens[0]) > 512):\n",
    "            print(\"LONG SENTENCE\")\n",
    "            # Append the next sentence to the chunk (this chunk will be truncated later).\n",
    "            chunk_tok.extend(indexed_tokens.pop(0))\n",
    "            chunk_sent.append(sentences.pop(0))\n",
    "\n",
    "        # While:\n",
    "        #   - There is still sentences to pop in the list;\n",
    "        #   - The length of the current chunk combined with the length of the next sentence to pop is lower than 512 tokens;\n",
    "        while (indexed_tokens) and ((len(chunk_tok) + len(indexed_tokens[0])) <= 512):\n",
    "            # Pop the next tokenized sentence and append it to the chunk.\n",
    "            chunk_tok.extend(indexed_tokens.pop(0))\n",
    "            chunk_sent.append(sentences.pop(0))\n",
    "\n",
    "        # Concat all sentences in a chunk and remove \\n.\n",
    "        chunk_sent = ' '.join(chunk_sent).replace('\\n', ' ')\n",
    "\n",
    "        # Add that chunk to my list of chunks.\n",
    "        token_chunks.append(chunk_tok)\n",
    "        sentence_chunks.append(chunk_sent)\n",
    "        \n",
    "    return token_chunks, sentence_chunks\n",
    "\n",
    "\n",
    "def pad_and_truncate_chunks(token_chunks):\n",
    "    \"\"\"\n",
    "    Given a list of tokenized chunks, pad/truncate them so that they all have the same length.\n",
    "    \"\"\"\n",
    "    # Define length of longest tokenized chunk in the batch.\n",
    "    lengths = [len(i) for i in token_chunks]\n",
    "    max_len = max(lengths) if max(lengths) <= 512 else 512\n",
    "\n",
    "    # Pad/truncate chunks.\n",
    "    padded_chunks = pad_sequences(token_chunks, maxlen=max_len, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "    return padded_chunks\n",
    "\n",
    "\n",
    "def create_attention_masks(padded_chunks):\n",
    "    \"\"\"\n",
    "    Given a list of tokenized padded chunks, create the attention masks for each of them.\n",
    "    \"\"\"\n",
    "    attention_masks = np.where(padded_chunks != 0, 1, 0)  #returns ndarray which is 1 if padded_tokens != 0 is True and 0 if False.\n",
    "    return attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model/tokenizer...\n",
      "   Loaded checkpoint '/raid/antoloui/Master-thesis/Code/_models/netbert-830000/'.\n",
      "Loading sentences from /raid/antoloui/Master-thesis/Data/Cleaned/dev.raw...\n",
      "   3753239 sentences loaded.\n",
      "Tokenizing sentences...\n",
      "   5000 sentences tokenized.\n",
      "Creating chunks of max 512 tokens...\n",
      "   395 chunks created.\n",
      "Padding/truncating the chunks...\n",
      "   395 chunks padded/truncated.\n",
      "Creating attention masks...\n",
      "   395 attention masks created.\n"
     ]
    }
   ],
   "source": [
    "filepath = '/raid/antoloui/Master-thesis/Data/Cleaned/dev.raw'\n",
    "model_name_or_path = '/raid/antoloui/Master-thesis/Code/_models/netbert-830000/'\n",
    "\n",
    "\n",
    "print(\"Loading pretrained model/tokenizer...\")\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name_or_path)\n",
    "model = BertModel.from_pretrained(model_name_or_path, output_hidden_states=True) # Will output all hidden_states.\n",
    "print(\"   Loaded checkpoint '{}'.\".format(model_name_or_path))\n",
    "\n",
    "print(\"Loading sentences from {}...\".format(filepath))\n",
    "sentences = load_sentences(filepath)\n",
    "print(\"   {} sentences loaded.\".format(len(sentences)))\n",
    "\n",
    "print(\"Tokenizing sentences...\")\n",
    "sentences = sentences[:5000]\n",
    "indexed_tokens = tokenize(tokenizer, sentences)\n",
    "print(\"   {} sentences tokenized.\".format(len(indexed_tokens)))\n",
    "\n",
    "print(\"Creating chunks of max 512 tokens...\")\n",
    "token_chunks, sentence_chunks = create_chunks(sentences, indexed_tokens)\n",
    "print(\"   {} chunks created.\".format(len(token_chunks)))\n",
    "\n",
    "print(\"Padding/truncating the chunks...\")\n",
    "padded_chunks = pad_and_truncate_chunks(token_chunks)\n",
    "print(\"   {} chunks padded/truncated.\".format(len(padded_chunks)))\n",
    "\n",
    "print(\"Creating attention masks...\")\n",
    "attention_masks = create_attention_masks(padded_chunks)\n",
    "print(\"   {} attention masks created.\".format(len(attention_masks)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Batches:   0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Encoding chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Batches: 100%|██████████| 40/40 [01:28<00:00,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Chunks embedded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def encode_chunks(model, device, sentence_chunks, padded_chunks, attention_masks, batch_size):\n",
    "    \"\"\"\n",
    "    Encoding sentences with CPU/GPU(s).\n",
    "    \n",
    "    Note that here 'parallel.DataParallelModel' is used, where 'parallel.py' is a script imported\n",
    "    from the ' PyTorch-Encoding' package: https://github.com/zhanghang1989/PyTorch-Encoding\n",
    "    The DataParallelModel deals better with balanced load on multi-GPU than torch.nn.DataParallel,\n",
    "    allowing to significantly increase the batch size per GPU.\n",
    "\n",
    "    However, once again, the utilisation of the GPUs is very volatile (never at 100% all the time).\n",
    "    \"\"\"\n",
    "    all_embeddings = []\n",
    "    iterator = range(0, len(sentence_chunks), batch_size)\n",
    "    for batch_idx in tqdm(iterator, desc=\"   Batches\"):\n",
    "        \n",
    "        # Get the batch indices.\n",
    "        batch_start = batch_idx\n",
    "        batch_end = min(batch_start + batch_size, len(sentence_chunks))\n",
    "        \n",
    "        # Get the current batch.\n",
    "        batch_input_ids = padded_chunks[batch_start:batch_end]\n",
    "        batch_attention_masks = attention_masks[batch_start:batch_end]\n",
    "        \n",
    "        # Convert model inputs to torch tensors and push them to GPUs.\n",
    "        batch_input_ids = torch.tensor(batch_input_ids)\n",
    "        batch_input_ids = batch_input_ids.to(device)\n",
    "        batch_attention_masks = torch.tensor(batch_attention_masks)\n",
    "        batch_attention_masks = batch_attention_masks.to(device)\n",
    "        \n",
    "        # Encode batch.\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # outputs is a list of 3-tuples where each 3-tuple is such that:\n",
    "            #  - output[0] is the last_hidden_state, i.e a tensor of shape (batch_size, sequence_length, hidden_size).\n",
    "            #  - output[1] is the pooler_output, i.e. a tensor of shape (batch_size, hidden_size) being the last layer hidden-state of the first token of the sequence (classification token).\n",
    "            #  - output[2] are all hidden_states, i.e. a 13-tuple of torch tensors of shape (batch_size, sequence_length, hidden_size): 12 encoders-outputs + initial embedding outputs.\n",
    "            outputs = model(batch_input_ids, attention_mask=batch_attention_masks)\n",
    "            \n",
    "        # Gather outputs from the different GPUs.\n",
    "        #last_hidden_states = gather_sentence_outputs(outputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "\n",
    "        # For each sentence, take the embeddings of its word from the last layer and represent that sentence by their average.\n",
    "        chunk_embeddings = [torch.mean(embeddings[:torch.squeeze((masks == 1).nonzero(), dim=1).shape[0]], dim=0).to('cpu').numpy() for embeddings, masks in zip(last_hidden_states, batch_attention_masks)]\n",
    "        all_embeddings.extend(chunk_embeddings)\n",
    "        \n",
    "    # Create dataframe for storing embeddings.\n",
    "    all_embeddings = np.array(all_embeddings)\n",
    "    cols = ['feat'+str(i+1) for i in range(all_embeddings.shape[1])]\n",
    "    df = pd.DataFrame(data=all_embeddings[:,:], columns=cols)\n",
    "    df['Chunk'] = sentence_chunks\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"   Encoding chunks...\")\n",
    "df = encode_chunks(model, device, sentence_chunks, padded_chunks, attention_masks, 10)\n",
    "print(\"   Chunks embedded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>feat7</th>\n",
       "      <th>feat8</th>\n",
       "      <th>feat9</th>\n",
       "      <th>feat10</th>\n",
       "      <th>...</th>\n",
       "      <th>feat760</th>\n",
       "      <th>feat761</th>\n",
       "      <th>feat762</th>\n",
       "      <th>feat763</th>\n",
       "      <th>feat764</th>\n",
       "      <th>feat765</th>\n",
       "      <th>feat766</th>\n",
       "      <th>feat767</th>\n",
       "      <th>feat768</th>\n",
       "      <th>Chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.189363</td>\n",
       "      <td>-0.130048</td>\n",
       "      <td>-0.112261</td>\n",
       "      <td>0.030019</td>\n",
       "      <td>0.173977</td>\n",
       "      <td>0.029032</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.033509</td>\n",
       "      <td>-0.021282</td>\n",
       "      <td>0.019294</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083900</td>\n",
       "      <td>-0.147276</td>\n",
       "      <td>-0.184282</td>\n",
       "      <td>0.047551</td>\n",
       "      <td>-0.018213</td>\n",
       "      <td>0.207356</td>\n",
       "      <td>0.142576</td>\n",
       "      <td>-0.043626</td>\n",
       "      <td>0.071253</td>\n",
       "      <td>MediaSense Terminology • Playback, page 1 • Bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.102125</td>\n",
       "      <td>-0.168929</td>\n",
       "      <td>-0.130700</td>\n",
       "      <td>0.106593</td>\n",
       "      <td>0.133147</td>\n",
       "      <td>0.025501</td>\n",
       "      <td>-0.109736</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.026999</td>\n",
       "      <td>0.031063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075209</td>\n",
       "      <td>-0.152484</td>\n",
       "      <td>-0.166840</td>\n",
       "      <td>0.042063</td>\n",
       "      <td>0.035189</td>\n",
       "      <td>0.107075</td>\n",
       "      <td>0.162909</td>\n",
       "      <td>-0.121656</td>\n",
       "      <td>0.085183</td>\n",
       "      <td>For other sessions in Cisco MediaSense User Gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.141492</td>\n",
       "      <td>-0.083923</td>\n",
       "      <td>-0.099955</td>\n",
       "      <td>0.138810</td>\n",
       "      <td>0.105259</td>\n",
       "      <td>-0.122188</td>\n",
       "      <td>-0.147850</td>\n",
       "      <td>0.074596</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>0.043998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059514</td>\n",
       "      <td>-0.250270</td>\n",
       "      <td>-0.222964</td>\n",
       "      <td>0.072229</td>\n",
       "      <td>-0.070169</td>\n",
       "      <td>0.114454</td>\n",
       "      <td>0.193807</td>\n",
       "      <td>-0.145606</td>\n",
       "      <td>-0.053496</td>\n",
       "      <td>A session can be live (active) or recorded (co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.129332</td>\n",
       "      <td>-0.059174</td>\n",
       "      <td>-0.092327</td>\n",
       "      <td>0.133588</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>-0.090347</td>\n",
       "      <td>-0.137022</td>\n",
       "      <td>0.052293</td>\n",
       "      <td>0.016732</td>\n",
       "      <td>0.024999</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046281</td>\n",
       "      <td>-0.223892</td>\n",
       "      <td>-0.290861</td>\n",
       "      <td>0.114154</td>\n",
       "      <td>-0.072899</td>\n",
       "      <td>0.082204</td>\n",
       "      <td>0.179868</td>\n",
       "      <td>-0.128829</td>\n",
       "      <td>-0.028522</td>\n",
       "      <td>Each instance corresponds directly to one inst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.069944</td>\n",
       "      <td>-0.123942</td>\n",
       "      <td>-0.151792</td>\n",
       "      <td>0.072241</td>\n",
       "      <td>0.116116</td>\n",
       "      <td>-0.056365</td>\n",
       "      <td>-0.179424</td>\n",
       "      <td>0.034179</td>\n",
       "      <td>-0.043523</td>\n",
       "      <td>0.097471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045592</td>\n",
       "      <td>-0.224050</td>\n",
       "      <td>-0.186254</td>\n",
       "      <td>0.059414</td>\n",
       "      <td>-0.038229</td>\n",
       "      <td>0.051380</td>\n",
       "      <td>0.153363</td>\n",
       "      <td>-0.141080</td>\n",
       "      <td>-0.024632</td>\n",
       "      <td>The data is load balanced between both servers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0.144772</td>\n",
       "      <td>-0.075381</td>\n",
       "      <td>-0.106285</td>\n",
       "      <td>0.138673</td>\n",
       "      <td>-0.012263</td>\n",
       "      <td>0.119993</td>\n",
       "      <td>-0.005872</td>\n",
       "      <td>-0.054749</td>\n",
       "      <td>0.172315</td>\n",
       "      <td>0.092370</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009337</td>\n",
       "      <td>-0.123435</td>\n",
       "      <td>-0.210681</td>\n",
       "      <td>0.011843</td>\n",
       "      <td>-0.149880</td>\n",
       "      <td>-0.058068</td>\n",
       "      <td>0.211883</td>\n",
       "      <td>-0.161663</td>\n",
       "      <td>0.063657</td>\n",
       "      <td>serial number (Optional) Displays information ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.235946</td>\n",
       "      <td>-0.121318</td>\n",
       "      <td>-0.150308</td>\n",
       "      <td>0.183412</td>\n",
       "      <td>-0.015245</td>\n",
       "      <td>0.063203</td>\n",
       "      <td>0.160002</td>\n",
       "      <td>0.066461</td>\n",
       "      <td>0.153953</td>\n",
       "      <td>-0.161887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052945</td>\n",
       "      <td>0.063293</td>\n",
       "      <td>-0.397960</td>\n",
       "      <td>0.056324</td>\n",
       "      <td>-0.165852</td>\n",
       "      <td>-0.091495</td>\n",
       "      <td>0.309324</td>\n",
       "      <td>-0.170412</td>\n",
       "      <td>0.033740</td>\n",
       "      <td>Because a specific bundle or bundle link is no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0.160374</td>\n",
       "      <td>-0.069715</td>\n",
       "      <td>0.030420</td>\n",
       "      <td>0.188667</td>\n",
       "      <td>0.031155</td>\n",
       "      <td>0.043820</td>\n",
       "      <td>0.146876</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.073386</td>\n",
       "      <td>-0.022806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>-0.032932</td>\n",
       "      <td>-0.384746</td>\n",
       "      <td>-0.117773</td>\n",
       "      <td>-0.137363</td>\n",
       "      <td>-0.209062</td>\n",
       "      <td>0.351914</td>\n",
       "      <td>-0.035939</td>\n",
       "      <td>0.085186</td>\n",
       "      <td>The example shows a bundle link in the \"idle\" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.150990</td>\n",
       "      <td>-0.096720</td>\n",
       "      <td>-0.082435</td>\n",
       "      <td>0.216195</td>\n",
       "      <td>0.045443</td>\n",
       "      <td>0.042745</td>\n",
       "      <td>0.136720</td>\n",
       "      <td>0.010465</td>\n",
       "      <td>0.056302</td>\n",
       "      <td>0.075066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027702</td>\n",
       "      <td>-0.071019</td>\n",
       "      <td>-0.340958</td>\n",
       "      <td>-0.040792</td>\n",
       "      <td>-0.112066</td>\n",
       "      <td>-0.176844</td>\n",
       "      <td>0.282540</td>\n",
       "      <td>-0.118444</td>\n",
       "      <td>0.023574</td>\n",
       "      <td>The example shows a bundle link in the \"up\" st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.074695</td>\n",
       "      <td>-0.106320</td>\n",
       "      <td>0.087370</td>\n",
       "      <td>0.146925</td>\n",
       "      <td>-0.160660</td>\n",
       "      <td>0.028503</td>\n",
       "      <td>0.057394</td>\n",
       "      <td>0.101547</td>\n",
       "      <td>0.116116</td>\n",
       "      <td>0.097731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151020</td>\n",
       "      <td>-0.342115</td>\n",
       "      <td>-0.369840</td>\n",
       "      <td>0.247023</td>\n",
       "      <td>0.099793</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>0.228039</td>\n",
       "      <td>-0.259373</td>\n",
       "      <td>-0.056234</td>\n",
       "      <td>Protocol state Operational state of the bundle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feat1     feat2     feat3     feat4     feat5     feat6     feat7  \\\n",
       "0    0.189363 -0.130048 -0.112261  0.030019  0.173977  0.029032  0.001942   \n",
       "1    0.102125 -0.168929 -0.130700  0.106593  0.133147  0.025501 -0.109736   \n",
       "2    0.141492 -0.083923 -0.099955  0.138810  0.105259 -0.122188 -0.147850   \n",
       "3    0.129332 -0.059174 -0.092327  0.133588  0.121212 -0.090347 -0.137022   \n",
       "4    0.069944 -0.123942 -0.151792  0.072241  0.116116 -0.056365 -0.179424   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "390  0.144772 -0.075381 -0.106285  0.138673 -0.012263  0.119993 -0.005872   \n",
       "391  0.235946 -0.121318 -0.150308  0.183412 -0.015245  0.063203  0.160002   \n",
       "392  0.160374 -0.069715  0.030420  0.188667  0.031155  0.043820  0.146876   \n",
       "393  0.150990 -0.096720 -0.082435  0.216195  0.045443  0.042745  0.136720   \n",
       "394  0.074695 -0.106320  0.087370  0.146925 -0.160660  0.028503  0.057394   \n",
       "\n",
       "        feat8     feat9    feat10  ...   feat760   feat761   feat762  \\\n",
       "0    0.033509 -0.021282  0.019294  ... -0.083900 -0.147276 -0.184282   \n",
       "1    0.001165  0.026999  0.031063  ... -0.075209 -0.152484 -0.166840   \n",
       "2    0.074596  0.038700  0.043998  ... -0.059514 -0.250270 -0.222964   \n",
       "3    0.052293  0.016732  0.024999  ... -0.046281 -0.223892 -0.290861   \n",
       "4    0.034179 -0.043523  0.097471  ... -0.045592 -0.224050 -0.186254   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "390 -0.054749  0.172315  0.092370  ... -0.009337 -0.123435 -0.210681   \n",
       "391  0.066461  0.153953 -0.161887  ...  0.052945  0.063293 -0.397960   \n",
       "392  0.003039  0.073386 -0.022806  ...  0.026316 -0.032932 -0.384746   \n",
       "393  0.010465  0.056302  0.075066  ...  0.027702 -0.071019 -0.340958   \n",
       "394  0.101547  0.116116  0.097731  ...  0.151020 -0.342115 -0.369840   \n",
       "\n",
       "      feat763   feat764   feat765   feat766   feat767   feat768  \\\n",
       "0    0.047551 -0.018213  0.207356  0.142576 -0.043626  0.071253   \n",
       "1    0.042063  0.035189  0.107075  0.162909 -0.121656  0.085183   \n",
       "2    0.072229 -0.070169  0.114454  0.193807 -0.145606 -0.053496   \n",
       "3    0.114154 -0.072899  0.082204  0.179868 -0.128829 -0.028522   \n",
       "4    0.059414 -0.038229  0.051380  0.153363 -0.141080 -0.024632   \n",
       "..        ...       ...       ...       ...       ...       ...   \n",
       "390  0.011843 -0.149880 -0.058068  0.211883 -0.161663  0.063657   \n",
       "391  0.056324 -0.165852 -0.091495  0.309324 -0.170412  0.033740   \n",
       "392 -0.117773 -0.137363 -0.209062  0.351914 -0.035939  0.085186   \n",
       "393 -0.040792 -0.112066 -0.176844  0.282540 -0.118444  0.023574   \n",
       "394  0.247023  0.099793  0.003055  0.228039 -0.259373 -0.056234   \n",
       "\n",
       "                                                 Chunk  \n",
       "0    MediaSense Terminology • Playback, page 1 • Bl...  \n",
       "1    For other sessions in Cisco MediaSense User Gu...  \n",
       "2    A session can be live (active) or recorded (co...  \n",
       "3    Each instance corresponds directly to one inst...  \n",
       "4    The data is load balanced between both servers...  \n",
       "..                                                 ...  \n",
       "390  serial number (Optional) Displays information ...  \n",
       "391  Because a specific bundle or bundle link is no...  \n",
       "392  The example shows a bundle link in the \"idle\" ...  \n",
       "393  The example shows a bundle link in the \"up\" st...  \n",
       "394  Protocol state Operational state of the bundle...  \n",
       "\n",
       "[395 rows x 769 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather all .h5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "      <th>feat3</th>\n",
       "      <th>feat4</th>\n",
       "      <th>feat5</th>\n",
       "      <th>feat6</th>\n",
       "      <th>feat7</th>\n",
       "      <th>feat8</th>\n",
       "      <th>feat9</th>\n",
       "      <th>feat10</th>\n",
       "      <th>...</th>\n",
       "      <th>feat760</th>\n",
       "      <th>feat761</th>\n",
       "      <th>feat762</th>\n",
       "      <th>feat763</th>\n",
       "      <th>feat764</th>\n",
       "      <th>feat765</th>\n",
       "      <th>feat766</th>\n",
       "      <th>feat767</th>\n",
       "      <th>feat768</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.280264</td>\n",
       "      <td>-0.099757</td>\n",
       "      <td>-0.038239</td>\n",
       "      <td>-0.098673</td>\n",
       "      <td>0.169518</td>\n",
       "      <td>-0.063823</td>\n",
       "      <td>0.735144</td>\n",
       "      <td>-0.032743</td>\n",
       "      <td>0.358951</td>\n",
       "      <td>0.097830</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058485</td>\n",
       "      <td>-0.256885</td>\n",
       "      <td>-0.130044</td>\n",
       "      <td>0.059638</td>\n",
       "      <td>-0.421342</td>\n",
       "      <td>-0.622948</td>\n",
       "      <td>-0.036204</td>\n",
       "      <td>0.172045</td>\n",
       "      <td>0.383999</td>\n",
       "      <td>G0, March 2007 Contents Features and Enhanceme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.366134</td>\n",
       "      <td>-0.208020</td>\n",
       "      <td>0.016205</td>\n",
       "      <td>-0.186076</td>\n",
       "      <td>0.144419</td>\n",
       "      <td>-0.004993</td>\n",
       "      <td>0.786685</td>\n",
       "      <td>-0.101411</td>\n",
       "      <td>0.297584</td>\n",
       "      <td>0.073194</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136041</td>\n",
       "      <td>-0.165522</td>\n",
       "      <td>-0.103805</td>\n",
       "      <td>0.129898</td>\n",
       "      <td>-0.474089</td>\n",
       "      <td>-0.556440</td>\n",
       "      <td>0.010095</td>\n",
       "      <td>0.145695</td>\n",
       "      <td>0.362004</td>\n",
       "      <td>p.#3# Contents Contents#.........................</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002002</td>\n",
       "      <td>-0.106297</td>\n",
       "      <td>-0.087648</td>\n",
       "      <td>0.122653</td>\n",
       "      <td>0.069144</td>\n",
       "      <td>-0.000705</td>\n",
       "      <td>0.156554</td>\n",
       "      <td>0.290996</td>\n",
       "      <td>-0.123224</td>\n",
       "      <td>0.104411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.222313</td>\n",
       "      <td>0.156713</td>\n",
       "      <td>-0.232677</td>\n",
       "      <td>0.059451</td>\n",
       "      <td>-0.381720</td>\n",
       "      <td>-0.044734</td>\n",
       "      <td>0.488280</td>\n",
       "      <td>-0.029846</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>Home Skip to content Skip to footer Worldwide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.062134</td>\n",
       "      <td>0.096518</td>\n",
       "      <td>-0.215182</td>\n",
       "      <td>0.196923</td>\n",
       "      <td>0.215821</td>\n",
       "      <td>-0.026429</td>\n",
       "      <td>0.116073</td>\n",
       "      <td>0.154525</td>\n",
       "      <td>0.014295</td>\n",
       "      <td>0.008637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110915</td>\n",
       "      <td>-0.049860</td>\n",
       "      <td>-0.352348</td>\n",
       "      <td>0.200215</td>\n",
       "      <td>-0.231690</td>\n",
       "      <td>-0.041897</td>\n",
       "      <td>0.323917</td>\n",
       "      <td>0.086202</td>\n",
       "      <td>0.141788</td>\n",
       "      <td>&lt;/p&gt; &lt;p&gt; The LocationStatus notification is ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.011293</td>\n",
       "      <td>0.080487</td>\n",
       "      <td>-0.148380</td>\n",
       "      <td>0.105190</td>\n",
       "      <td>0.015003</td>\n",
       "      <td>-0.095529</td>\n",
       "      <td>0.086479</td>\n",
       "      <td>0.201846</td>\n",
       "      <td>0.065185</td>\n",
       "      <td>0.065424</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.223511</td>\n",
       "      <td>-0.035504</td>\n",
       "      <td>-0.419971</td>\n",
       "      <td>0.071184</td>\n",
       "      <td>-0.241609</td>\n",
       "      <td>0.055943</td>\n",
       "      <td>0.262380</td>\n",
       "      <td>0.064603</td>\n",
       "      <td>0.171011</td>\n",
       "      <td>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;comman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>-0.193245</td>\n",
       "      <td>0.434848</td>\n",
       "      <td>0.811894</td>\n",
       "      <td>-0.410603</td>\n",
       "      <td>-0.315942</td>\n",
       "      <td>-0.935870</td>\n",
       "      <td>0.051716</td>\n",
       "      <td>-0.511334</td>\n",
       "      <td>0.347976</td>\n",
       "      <td>-1.574084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662778</td>\n",
       "      <td>0.453332</td>\n",
       "      <td>-0.555245</td>\n",
       "      <td>0.254290</td>\n",
       "      <td>0.050753</td>\n",
       "      <td>-0.323471</td>\n",
       "      <td>-0.621548</td>\n",
       "      <td>-0.529996</td>\n",
       "      <td>-0.624799</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>-0.193245</td>\n",
       "      <td>0.434848</td>\n",
       "      <td>0.811894</td>\n",
       "      <td>-0.410603</td>\n",
       "      <td>-0.315942</td>\n",
       "      <td>-0.935870</td>\n",
       "      <td>0.051716</td>\n",
       "      <td>-0.511334</td>\n",
       "      <td>0.347976</td>\n",
       "      <td>-1.574084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662778</td>\n",
       "      <td>0.453332</td>\n",
       "      <td>-0.555245</td>\n",
       "      <td>0.254290</td>\n",
       "      <td>0.050753</td>\n",
       "      <td>-0.323471</td>\n",
       "      <td>-0.621548</td>\n",
       "      <td>-0.529996</td>\n",
       "      <td>-0.624799</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>-0.193245</td>\n",
       "      <td>0.434848</td>\n",
       "      <td>0.811894</td>\n",
       "      <td>-0.410603</td>\n",
       "      <td>-0.315942</td>\n",
       "      <td>-0.935870</td>\n",
       "      <td>0.051716</td>\n",
       "      <td>-0.511334</td>\n",
       "      <td>0.347976</td>\n",
       "      <td>-1.574084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662778</td>\n",
       "      <td>0.453332</td>\n",
       "      <td>-0.555245</td>\n",
       "      <td>0.254290</td>\n",
       "      <td>0.050753</td>\n",
       "      <td>-0.323471</td>\n",
       "      <td>-0.621548</td>\n",
       "      <td>-0.529996</td>\n",
       "      <td>-0.624799</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>-0.193245</td>\n",
       "      <td>0.434848</td>\n",
       "      <td>0.811894</td>\n",
       "      <td>-0.410603</td>\n",
       "      <td>-0.315942</td>\n",
       "      <td>-0.935870</td>\n",
       "      <td>0.051716</td>\n",
       "      <td>-0.511334</td>\n",
       "      <td>0.347976</td>\n",
       "      <td>-1.574084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662778</td>\n",
       "      <td>0.453332</td>\n",
       "      <td>-0.555245</td>\n",
       "      <td>0.254290</td>\n",
       "      <td>0.050753</td>\n",
       "      <td>-0.323471</td>\n",
       "      <td>-0.621548</td>\n",
       "      <td>-0.529996</td>\n",
       "      <td>-0.624799</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>-0.193245</td>\n",
       "      <td>0.434848</td>\n",
       "      <td>0.811894</td>\n",
       "      <td>-0.410603</td>\n",
       "      <td>-0.315942</td>\n",
       "      <td>-0.935870</td>\n",
       "      <td>0.051716</td>\n",
       "      <td>-0.511334</td>\n",
       "      <td>0.347976</td>\n",
       "      <td>-1.574084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662778</td>\n",
       "      <td>0.453332</td>\n",
       "      <td>-0.555245</td>\n",
       "      <td>0.254290</td>\n",
       "      <td>0.050753</td>\n",
       "      <td>-0.323471</td>\n",
       "      <td>-0.621548</td>\n",
       "      <td>-0.529996</td>\n",
       "      <td>-0.624799</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           feat1     feat2     feat3     feat4     feat5     feat6     feat7  \\\n",
       "0      -0.280264 -0.099757 -0.038239 -0.098673  0.169518 -0.063823  0.735144   \n",
       "1      -0.366134 -0.208020  0.016205 -0.186076  0.144419 -0.004993  0.786685   \n",
       "2      -0.002002 -0.106297 -0.087648  0.122653  0.069144 -0.000705  0.156554   \n",
       "3      -0.062134  0.096518 -0.215182  0.196923  0.215821 -0.026429  0.116073   \n",
       "4      -0.011293  0.080487 -0.148380  0.105190  0.015003 -0.095529  0.086479   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "999995 -0.193245  0.434848  0.811894 -0.410603 -0.315942 -0.935870  0.051716   \n",
       "999996 -0.193245  0.434848  0.811894 -0.410603 -0.315942 -0.935870  0.051716   \n",
       "999997 -0.193245  0.434848  0.811894 -0.410603 -0.315942 -0.935870  0.051716   \n",
       "999998 -0.193245  0.434848  0.811894 -0.410603 -0.315942 -0.935870  0.051716   \n",
       "999999 -0.193245  0.434848  0.811894 -0.410603 -0.315942 -0.935870  0.051716   \n",
       "\n",
       "           feat8     feat9    feat10  ...   feat760   feat761   feat762  \\\n",
       "0      -0.032743  0.358951  0.097830  ... -0.058485 -0.256885 -0.130044   \n",
       "1      -0.101411  0.297584  0.073194  ... -0.136041 -0.165522 -0.103805   \n",
       "2       0.290996 -0.123224  0.104411  ... -0.222313  0.156713 -0.232677   \n",
       "3       0.154525  0.014295  0.008637  ... -0.110915 -0.049860 -0.352348   \n",
       "4       0.201846  0.065185  0.065424  ... -0.223511 -0.035504 -0.419971   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "999995 -0.511334  0.347976 -1.574084  ...  0.662778  0.453332 -0.555245   \n",
       "999996 -0.511334  0.347976 -1.574084  ...  0.662778  0.453332 -0.555245   \n",
       "999997 -0.511334  0.347976 -1.574084  ...  0.662778  0.453332 -0.555245   \n",
       "999998 -0.511334  0.347976 -1.574084  ...  0.662778  0.453332 -0.555245   \n",
       "999999 -0.511334  0.347976 -1.574084  ...  0.662778  0.453332 -0.555245   \n",
       "\n",
       "         feat763   feat764   feat765   feat766   feat767   feat768  \\\n",
       "0       0.059638 -0.421342 -0.622948 -0.036204  0.172045  0.383999   \n",
       "1       0.129898 -0.474089 -0.556440  0.010095  0.145695  0.362004   \n",
       "2       0.059451 -0.381720 -0.044734  0.488280 -0.029846  0.007652   \n",
       "3       0.200215 -0.231690 -0.041897  0.323917  0.086202  0.141788   \n",
       "4       0.071184 -0.241609  0.055943  0.262380  0.064603  0.171011   \n",
       "...          ...       ...       ...       ...       ...       ...   \n",
       "999995  0.254290  0.050753 -0.323471 -0.621548 -0.529996 -0.624799   \n",
       "999996  0.254290  0.050753 -0.323471 -0.621548 -0.529996 -0.624799   \n",
       "999997  0.254290  0.050753 -0.323471 -0.621548 -0.529996 -0.624799   \n",
       "999998  0.254290  0.050753 -0.323471 -0.621548 -0.529996 -0.624799   \n",
       "999999  0.254290  0.050753 -0.323471 -0.621548 -0.529996 -0.624799   \n",
       "\n",
       "                                                 Sentence  \n",
       "0       G0, March 2007 Contents Features and Enhanceme...  \n",
       "1       p.#3# Contents Contents#.........................  \n",
       "2       Home Skip to content Skip to footer Worldwide ...  \n",
       "3       </p> <p> The LocationStatus notification is ge...  \n",
       "4       <?xml version=\"1.0\" encoding=\"UTF-8\"?> <comman...  \n",
       "...                                                   ...  \n",
       "999995                                                 \\n  \n",
       "999996                                                 \\n  \n",
       "999997                                                 \\n  \n",
       "999998                                                 \\n  \n",
       "999999                                                 \\n  \n",
       "\n",
       "[1000000 rows x 769 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirpath = '/raid/antoloui/Master-thesis/Data/Embeddings/'\n",
    "filename = 'dev00.h5'\n",
    "\n",
    "# Open dataframe.\n",
    "df = pd.read_hdf(dirpath + filename)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicated rows: 304792. Only keeping one sample for each duplicate...\n",
      "\n",
      "Number of duplicated rows: 237604. Only keeping one sample for each duplicate...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNumber of duplicated rows: {}. Only keeping one sample for each duplicate...\".format(df[df.duplicated(['Sentence'])].shape[0]))\n",
    "print(\"\\nNumber of duplicated rows: {}. Only keeping one sample for each duplicate...\".format(df[df.duplicated()].shape[0]))\n",
    "#original_df.drop_duplicates(subset=['Sentence'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
