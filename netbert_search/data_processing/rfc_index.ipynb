{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import wget\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download all RFC files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_rfc(base_url, outdir, total_rfc):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Create output directory if not exists.\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    # Download all RFCs.\n",
    "    errors = []\n",
    "    for i in tqdm(range(total_rfc)):\n",
    "        # Create the url.\n",
    "        url = base_url + str(i+1) + '.txt'\n",
    "\n",
    "        # Download page.\n",
    "        try:\n",
    "            wget.download(url, outdir)\n",
    "        except Exception as e:\n",
    "            errors.append(i+1)\n",
    "            print(\"RFC {}: HTTP Error 404 - Not Found.\".format(i+1))\n",
    "            \n",
    "    # Save 404 errors.\n",
    "    with open(os.path.join(outdir, 'errors404'), 'wb') as out:\n",
    "        pickle.dump(errors, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615a6033198d47849709aa2a6f13aea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC 8: HTTP Error 404 - Not Found.\n",
      "RFC 9: HTTP Error 404 - Not Found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "download_rfc(base_url='https://tools.ietf.org/rfc/rfc', \n",
    "             outdir='/raid/antoloui/Master-thesis/_data/search/rfc', \n",
    "             total_rfc=8774)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create clean dataframe from RFC index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_rfc_lines(lines):\n",
    "    \"\"\"\n",
    "    Given a list of lines where a same RFC is described on multiple lines, concat\n",
    "    the lines describing the same RFC.\n",
    "    \"\"\"\n",
    "    rfc_lines = []\n",
    "    current_rfc = ''\n",
    "    for line in lines:\n",
    "        if line.startswith('RFC'):\n",
    "            rfc_lines.append(current_rfc)  # End of previous RFC, append it to list.\n",
    "            current_rfc = line  # Get beginning of new rfc.\n",
    "        else:\n",
    "            current_rfc += line\n",
    "    return rfc_lines\n",
    "\n",
    "\n",
    "def remove_multiple_spaces(text):\n",
    "    \"\"\"\n",
    "    Given a string, replace all multiple spaces in it by a single space.\n",
    "    \"\"\"\n",
    "    text = re.sub('\\s{2,}', ' ', text)\n",
    "    text = text.lstrip().rstrip()  # Remove whitespaces in beginning or end of string.\n",
    "    return text\n",
    "    \n",
    "\n",
    "def get_rfc_lines(page, errors_filepath):\n",
    "    \"\"\"\n",
    "    Given the result of an url request, get the text of interest.\n",
    "    \"\"\"\n",
    "    # Load the page with BeautifulSoup.\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # Get the text of interest (the index is in <pre>...</pre>).\n",
    "    body = soup('pre')[0]\n",
    "    \n",
    "    # Get plain text.\n",
    "    content = body.get_text() \n",
    "    \n",
    "    # Remove all text before the line beginning by 'RFC1' (beginning of the index).\n",
    "    content = content.split('RFC1 ')[1]\n",
    "    content = 'RFC1 ' + content\n",
    "    \n",
    "    # Split raw text to lines.\n",
    "    lines = content.splitlines()\n",
    "    lines = [line for line in lines if line != ''] # remove empty lines.\n",
    "    \n",
    "    # Concat lines describing the same RFC.\n",
    "    rfc_lines = concat_rfc_lines(lines)\n",
    "    \n",
    "    # Remove multiple spaces.\n",
    "    rfc_lines = [remove_multiple_spaces(line) for line in rfc_lines]\n",
    "    \n",
    "    # Remove all 'Non Issued' RFCs.\n",
    "    rfc_lines = [line for line in rfc_lines if 'Not Issued' not in line]\n",
    "    \n",
    "    # Remove RFC that were not found during download.\n",
    "    with open(errors_filepath, \"rb\") as f:\n",
    "        errors = pickle.load(f)\n",
    "    rfc_lines = [line for line in rfc_lines if int(line.split(' ', 1)[0].split('RFC')[1]) not in set(errors)]\n",
    "    \n",
    "    return rfc_lines[1:]\n",
    "\n",
    "\n",
    "def create_dataframe(rfc_lines):\n",
    "    \"\"\"\n",
    "    Given the lines describing each RFC, create a dataframe.\n",
    "    \"\"\"\n",
    "    # Init lists.\n",
    "    names = []\n",
    "    titles = []\n",
    "    authors = []\n",
    "    dates = []\n",
    "    formats = []\n",
    "    obsolotes = []\n",
    "    obsoloted = []\n",
    "    updates = []\n",
    "    updated = []\n",
    "    also = []\n",
    "    status = []\n",
    "    dois = []\n",
    "    \n",
    "    # Process each line.\n",
    "    for i, line in enumerate(tqdm(rfc_lines)):\n",
    "        \n",
    "        # Get all attributes within brackets.\n",
    "        brackets = re.findall(r\"\\((.*?)\\)\", line)\n",
    "\n",
    "        # Get individual attributes.\n",
    "        form = None\n",
    "        obs = None\n",
    "        obs_by = None\n",
    "        up = None\n",
    "        up_by = None\n",
    "        al = None\n",
    "        stat = None\n",
    "        doi = None\n",
    "        for att in brackets:\n",
    "            if att.startswith('Format: '):\n",
    "                form = att.split('Format: ')[1]\n",
    "            elif att.startswith('Obsolotes '):\n",
    "                obs = att.split('Obsolotes ')[1]\n",
    "            elif att.startswith('Obsoleted by '):\n",
    "                obs_by = att.split('Obsoleted by ')[1]\n",
    "            elif att.startswith('Updates '):\n",
    "                up = att.split('Updates ')[1]\n",
    "            elif att.startswith('Updated by '):\n",
    "                up_by = att.split('Updated by ')[1]\n",
    "            elif att.startswith('Also '):\n",
    "                al = att.split('Also ')[1]\n",
    "            elif att.startswith('Status: '):\n",
    "                stat = att.split('Status: ')[1]\n",
    "            elif att.startswith('DOI: '):\n",
    "                doi = att.split('DOI: ')[1]\n",
    "        line = line.split('(Format')[0].rstrip()  # Remove bracket attributes from the line.\n",
    "\n",
    "        # Get the date of publication.\n",
    "        split_line = line.split(\".\")\n",
    "        split_line = [l for l in split_line if l != '']\n",
    "        date = split_line[-1].lstrip()\n",
    "        line = line.replace(date + '.', '')  # Remove date from line.\n",
    "\n",
    "        # Get name of RFC.\n",
    "        name = line.split()[0]\n",
    "        line = line.replace(name, '')  # Remove name from line.\n",
    "\n",
    "        # Get title of RFC.\n",
    "        title = line.split('.')[0].lstrip()\n",
    "        line = line.replace(title + '.', '')  # Remove title from line.\n",
    "\n",
    "        # Get authors.\n",
    "        aut = line.lstrip().rstrip()[:-1]\n",
    "\n",
    "        # Append all info to corresponding list.\n",
    "        names.append(name)\n",
    "        titles.append(title)\n",
    "        authors.append(aut)\n",
    "        dates.append(date)\n",
    "        formats.append(form)\n",
    "        obsolotes.append(obs)\n",
    "        obsoloted.append(obs_by)\n",
    "        updates.append(up)\n",
    "        updated.append(up_by)\n",
    "        also.append(al)\n",
    "        status.append(stat)\n",
    "        dois.append(doi)\n",
    "\n",
    "    # Create dataframe.\n",
    "    d = {'Name':names,\n",
    "         'Ttile':titles,\n",
    "         'Authors':authors,\n",
    "         'Date':dates,\n",
    "         'Formats':formats,\n",
    "         'Obsolotes':obsolotes,\n",
    "         'Obsoloted_by':obsoloted,\n",
    "         'Updates':updates,\n",
    "         'Updated_by':updated,\n",
    "         'Also_FYI':also,\n",
    "         'Status':status,\n",
    "         'DOI':dois}\n",
    "    df = pd.DataFrame(d)\n",
    "    return df\n",
    "        \n",
    "\n",
    "def main(url, errors_filepath):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Download the page.\n",
    "    page = requests.get(url)\n",
    "    \n",
    "    # Get all RFC lines.\n",
    "    rfc_lines = get_rfc_lines(page, errors_filepath)\n",
    "    \n",
    "    # Create dataframe.\n",
    "    df = create_dataframe(rfc_lines)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main(url='https://tools.ietf.org/rfc/index', \n",
    "          errors_filepath='/raid/antoloui/Master-thesis/_data/search/rfc/errors404')\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
