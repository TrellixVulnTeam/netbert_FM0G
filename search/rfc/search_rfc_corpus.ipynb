{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFC Corpus Search\n",
    "Given a query (question), search the best corresponding chunks among all RFC standards listing [here](https://tools.ietf.org/rfc/index).\n",
    "\n",
    "**FAISS**: The search operation is performed by Facebook AI Similarity Search (FAISS) library, which has an excellent GPU implementation of \"brute-force\" kNN (meaning that no approximation techniques compromising the accuracy of the search)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialization\n",
    "\n",
    "The 'Initialization' cell will load in memory the FAISS index created for the corpus. Hence, that cell needs to be run only once after starting the notebook.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Run the cell.\n",
    "2. Choose the type of FAISS index.\n",
    "3. Choose the number of GPUs you want to use for the search (the more the faster).\n",
    "4. Click on the 'Init' button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b029662cde7c4a629ab18ab592b7d39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Index:', options=('L2', 'Inner-Product', 'Cosine'), value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import faiss\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "#                                  CODE\n",
    "#---------------------------------------------------------------------------\n",
    "def format_time(elapsed):\n",
    "    \"\"\"\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    \"\"\"\n",
    "    return str(datetime.timedelta(seconds=int(round((elapsed)))))\n",
    "\n",
    "\n",
    "def init(dirpath, method, n_gpu):\n",
    "    \"\"\"\n",
    "    Load FAISS index and all text chunks.\n",
    "    \"\"\"\n",
    "    # Get the method.\n",
    "    index_name = 'l2' if method=='L2' else 'ip' if method=='Inner-Product' else 'cos'\n",
    "    \n",
    "    # Load FAISS index.\n",
    "    if os.path.exists(os.path.join(dirpath, index_name + \".index\")):\n",
    "        index = faiss.read_index(os.path.join(dirpath, index_name + \".index\"))\n",
    "        if n_gpu > 0 and faiss.get_num_gpus() > 0:\n",
    "            if n_gpu > faiss.get_num_gpus(): n_gpu = faiss.get_num_gpus()\n",
    "            co = faiss.GpuMultipleClonerOptions()  # If using multiple GPUs, enable sharding so that the dataset is divided across the GPUs rather than replicated.\n",
    "            co.shard = True\n",
    "            index = faiss.index_cpu_to_all_gpus(index, co=co, ngpu=n_gpu)  # Convert CPU index to GPU index.\n",
    "    else:\n",
    "        print(\"Error: no index found in {}... Make sure to create the index before searching in corpus. Exiting...\".format(dirpath))\n",
    "        sys.exit(0)\n",
    "        \n",
    "    # Load text chunks.\n",
    "    if os.path.exists(os.path.join(dirpath, \"chunks.txt\")):\n",
    "        with open(os.path.join(dirpath, \"chunks.txt\"), \"rb\") as f:\n",
    "            chunks = pickle.load(f)\n",
    "    else:\n",
    "        print(\"Error: no chunks found in {}... Make sure to create the index before searching in corpus. Exiting...\".format(dirpath))\n",
    "        sys.exit(0)\n",
    "    \n",
    "    return index, chunks\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "#                                 WIDGETS\n",
    "#---------------------------------------------------------------------------\n",
    "# Index dropdown list.\n",
    "options = ['L2', 'Inner-Product', 'Cosine']\n",
    "choose_index = widgets.Dropdown(\n",
    "    options=options,\n",
    "    value='L2',\n",
    "    description='Index:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# GPUs dropdown list.\n",
    "nb_gpus = list(range(faiss.get_num_gpus()+1))\n",
    "nb_gpus = list(map(str, nb_gpus))\n",
    "choose_gpus = widgets.Dropdown(\n",
    "    options=nb_gpus,\n",
    "    value='8',\n",
    "    description='GPUs:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Button for loading FAISS index.\n",
    "init_btn = widgets.Button(description='Init')\n",
    "init_out = widgets.Output()\n",
    "def init_btn_eventhandler(obj):\n",
    "    init_out.clear_output()  # Clear output.\n",
    "    gpus = int(choose_gpus.value) # Get the GPUs value from dropdown.\n",
    "    with init_out:\n",
    "        print(\"\\nLoading FAISS index with {} GPUs...\".format(gpus))\n",
    "        t0 = time.time()\n",
    "        global index, chunks\n",
    "        index, chunks = init(dirpath='/raid/antoloui/Master-thesis/_data/search/rfc/index/',\n",
    "                             method=choose_index.value, \n",
    "                             n_gpu=gpus)\n",
    "        print(\"  Done.  -  Took: {}\".format(format_time(time.time() - t0)))\n",
    "init_btn.on_click(init_btn_eventhandler)\n",
    "\n",
    "# Display widgets.\n",
    "box = widgets.HBox([choose_index, choose_gpus, init_btn])\n",
    "widgets.VBox([box, init_out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Search\n",
    "\n",
    "Given a query, the 'Search' cell will return the top-k most similar text chunks from the corpus.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Run the cell.\n",
    "2. Type a query.\n",
    "3. Choose the number of results to display.\n",
    "4. Click on the 'Search' button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91be143dea8d4057b77bbff5dd8538fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='', description='Query:', layout=Layout(width='50%'), placeholder='Ty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "#                                  CODE\n",
    "#---------------------------------------------------------------------------\n",
    "def encode_queries(model, tokenizer, sentences):\n",
    "    \"\"\"\n",
    "    Given a list of sentences, get the embeddings of their embeddings with NetBERT\n",
    "    as the average of the word embeddings of the last layer (padding tokens excluded).\n",
    "    \"\"\"\n",
    "    #Tokenizing sentences.\n",
    "    tokenized = [tokenizer.encode(sent, add_special_tokens=True) for sent in sentences]\n",
    "\n",
    "    lengths = [len(i) for i in tokenized]\n",
    "    max_len = max(lengths) if max(lengths) <= 512 else 512\n",
    "\n",
    "    #Padding/Truncating sentences to max_len tokens.\n",
    "    padded = pad_sequences(tokenized, maxlen=max_len, dtype=\"long\", \n",
    "                           value=0, truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    #Creating attention masks.\n",
    "    attention_mask = np.where(padded != 0, 1, 0)  #returns ndarray which is 1 if padded != 0 is True and 0 if False.\n",
    "\n",
    "    # Converting inputs to torch tensors.\n",
    "    input_ids = torch.tensor(padded)  \n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "    # Encoding sentences.\n",
    "    with torch.no_grad():\n",
    "        # output is a 2-tuple where:\n",
    "        #  - output[0] is the last_hidden_state, i.e a tensor of shape (batch_size, sequence_length, hidden_size).\n",
    "        #  - output[1] is the pooler_output, i.e. a tensor of shape (batch_size, hidden_size) being the last layer hidden-state of the first token of the sequence (classification token).\n",
    "        #  - output[2] are all hidden_states, i.e. a 13-tuple of torch tensors of shape (batch_size, sequence_length, hidden_size): 12 encoders-outputs + initial embedding outputs.\n",
    "        output = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # For each sentence, take the embeddings of its word from the last layer and represent that sentence by their average.\n",
    "    last_hidden_states = output[0]\n",
    "    sentence_embeddings = [torch.mean(embeddings[:torch.squeeze((masks == 1).nonzero(), dim=1).shape[0]], dim=0).numpy() for embeddings, masks in zip(last_hidden_states, attention_mask)]\n",
    "    sentence_embeddings = np.array(sentence_embeddings)\n",
    "    \n",
    "    return sentence_embeddings\n",
    "\n",
    "\n",
    "def load_model(model_name_or_path):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Loading pretrained model/tokenizer.\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name_or_path)\n",
    "    model = BertModel.from_pretrained(model_name_or_path, output_hidden_states=True) # Will output all hidden_states.\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def search_corpus(model, tokenizer, query, index, chunks, topk):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    start_total = time.time()\n",
    "    \n",
    "    # Encode query with NetBERT.\n",
    "    start_encode = time.time()\n",
    "    query_embedding = encode_queries(model, tokenizer, [query])[0]\n",
    "    end_encode = time.time()\n",
    "    \n",
    "    # Search topk results.\n",
    "    start_search = time.time()\n",
    "    result_dist, result_idx = index.search(query_embedding.reshape(1,768), k=topk)\n",
    "    end_search = time.time()\n",
    "    \n",
    "    end_total = time.time()\n",
    "    \n",
    "    # Display topk results.\n",
    "    for i, (idx, dist) in enumerate(zip(result_idx[0], result_dist[0])):\n",
    "        print(\"\\nTop {} result - (Distance: {:.3f})\".format(i+1, dist))\n",
    "        print(\"---------------------------\")\n",
    "        print(chunks[idx])\n",
    "        \n",
    "    # Display search time.\n",
    "    print(\"\\n** Search time **\")\n",
    "    print(\"  Encoding query: {:.3f}\".format(end_encode-start_encode))\n",
    "    print(\"  Faiss search: {:.3f}\".format(end_search-start_search))\n",
    "    print(\"  (Total search time: {:.3f})\".format(end_total - start_total))\n",
    "    \n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "#                                 WIDGETS\n",
    "#---------------------------------------------------------------------------\n",
    "# Text widget for typing in query.\n",
    "choose_query = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type your query',\n",
    "    description='Query:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "\n",
    "\n",
    "# Slider widget for choosing topk results value.\n",
    "choose_topk = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=1,\n",
    "    max=50,\n",
    "    step=1,\n",
    "    description='Topk:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "# Button widget for launching the search.\n",
    "search_btn = widgets.Button(description='Search')\n",
    "search_out = widgets.Output()\n",
    "model, tokenizer = load_model(model_name_or_path='/raid/antoloui/Master-thesis/_models/netbert-final/')\n",
    "def search_btn_eventhandler(obj):\n",
    "    search_out.clear_output()  # Clear output.\n",
    "    global model\n",
    "    global tokenizer\n",
    "    with search_out:\n",
    "        search_corpus(model=model, \n",
    "                      tokenizer=tokenizer,\n",
    "                      query=choose_query.value, \n",
    "                      index=index, \n",
    "                      chunks=chunks, \n",
    "                      topk=choose_topk.value)\n",
    "search_btn.on_click(search_btn_eventhandler)\n",
    "\n",
    "# Display widgets.\n",
    "box = widgets.HBox([choose_query, choose_topk, search_btn])\n",
    "widgets.VBox([box, search_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of 'chunks.txt': 0.4575 GB\n",
      "Size of 'cos.index': 3.7392 GB\n",
      "Size of 'ip.index': 3.7392 GB\n",
      "Size of 'l2.index': 3.7392 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory = '/raid/antoloui/Master-thesis/_data/search/rfc/index/'\n",
    "files = os.listdir(directory).sort()\n",
    "\n",
    "\n",
    "# Check size of an index.\n",
    "total_size = 0\n",
    "for filename in sorted(os.listdir(directory)):\n",
    "    file_path = directory + filename\n",
    "    size = os.path.getsize(file_path)/(1024*1024*1024)\n",
    "    total_size += size\n",
    "    print(\"Size of '{}': {:.4f} GB\".format(filename, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1306931"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Date</th>\n",
       "      <th>Formats</th>\n",
       "      <th>Obsolotes</th>\n",
       "      <th>Obsoloted_by</th>\n",
       "      <th>Updates</th>\n",
       "      <th>Updated_by</th>\n",
       "      <th>Also_FYI</th>\n",
       "      <th>Status</th>\n",
       "      <th>DOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>rfc1</td>\n",
       "      <td>Host Software</td>\n",
       "      <td>S. Crocker</td>\n",
       "      <td>April 1969</td>\n",
       "      <td>TXT, HTML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>10.17487/RFC0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rfc2</td>\n",
       "      <td>Host software</td>\n",
       "      <td>B. Duvall</td>\n",
       "      <td>April 1969</td>\n",
       "      <td>TXT, PDF, HTML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>10.17487/RFC0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rfc3</td>\n",
       "      <td>Documentation conventions</td>\n",
       "      <td>S.D. Crocker</td>\n",
       "      <td>April 1969</td>\n",
       "      <td>TXT, HTML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RFC0010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>10.17487/RFC0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>rfc4</td>\n",
       "      <td>Network timetable</td>\n",
       "      <td>E.B. Shapiro</td>\n",
       "      <td>March 1969</td>\n",
       "      <td>TXT, HTML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>10.17487/RFC0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>rfc5</td>\n",
       "      <td>Decode Encode Language (DEL)</td>\n",
       "      <td>J. Rulifson</td>\n",
       "      <td>June 1969</td>\n",
       "      <td>TXT, HTML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>10.17487/RFC0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8565</th>\n",
       "      <td>8571</td>\n",
       "      <td>rfc8769</td>\n",
       "      <td>Cryptographic Message Syntax (CMS) Content Ty...</td>\n",
       "      <td>J. Schaad</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>HTML, TXT, PDF, XML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INFORMATIONAL</td>\n",
       "      <td>10.17487/RFC8769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8566</th>\n",
       "      <td>8572</td>\n",
       "      <td>rfc8770</td>\n",
       "      <td>Host Router Support for OSPFv2</td>\n",
       "      <td>K. Patel, P. Pillay-Esnault, M. Bhardwaj, S. B...</td>\n",
       "      <td>April 2020</td>\n",
       "      <td>HTML, TXT, PDF, XML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RFC6987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROPOSED STANDARD</td>\n",
       "      <td>10.17487/RFC8770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8567</th>\n",
       "      <td>8573</td>\n",
       "      <td>rfc8771</td>\n",
       "      <td>The Internationalized Deliberately Unreadable...</td>\n",
       "      <td>A. Mayrhofer, J. Hague</td>\n",
       "      <td>1 April 2020</td>\n",
       "      <td>HTML, TXT, PDF, XML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EXPERIMENTAL</td>\n",
       "      <td>10.17487/RFC8771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8568</th>\n",
       "      <td>8574</td>\n",
       "      <td>rfc8773</td>\n",
       "      <td>TLS 1.3 Extension for Certificate-Based Authe...</td>\n",
       "      <td>R. Housley</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>HTML, TXT, PDF, XML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EXPERIMENTAL</td>\n",
       "      <td>10.17487/RFC8773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8569</th>\n",
       "      <td>8575</td>\n",
       "      <td>rfc8774</td>\n",
       "      <td>The Quantum Bug</td>\n",
       "      <td>M. Welzl</td>\n",
       "      <td>1 April 2020</td>\n",
       "      <td>HTML, TXT, PDF, XML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INFORMATIONAL</td>\n",
       "      <td>10.17487/RFC8774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8570 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0     Name                                              Title  \\\n",
       "0              0     rfc1                                      Host Software   \n",
       "1              1     rfc2                                      Host software   \n",
       "2              2     rfc3                          Documentation conventions   \n",
       "3              3     rfc4                                  Network timetable   \n",
       "4              4     rfc5                       Decode Encode Language (DEL)   \n",
       "...          ...      ...                                                ...   \n",
       "8565        8571  rfc8769   Cryptographic Message Syntax (CMS) Content Ty...   \n",
       "8566        8572  rfc8770                     Host Router Support for OSPFv2   \n",
       "8567        8573  rfc8771   The Internationalized Deliberately Unreadable...   \n",
       "8568        8574  rfc8773   TLS 1.3 Extension for Certificate-Based Authe...   \n",
       "8569        8575  rfc8774                                    The Quantum Bug   \n",
       "\n",
       "                                                Authors          Date  \\\n",
       "0                                            S. Crocker    April 1969   \n",
       "1                                             B. Duvall    April 1969   \n",
       "2                                          S.D. Crocker    April 1969   \n",
       "3                                          E.B. Shapiro    March 1969   \n",
       "4                                           J. Rulifson     June 1969   \n",
       "...                                                 ...           ...   \n",
       "8565                                          J. Schaad    March 2020   \n",
       "8566  K. Patel, P. Pillay-Esnault, M. Bhardwaj, S. B...    April 2020   \n",
       "8567                             A. Mayrhofer, J. Hague  1 April 2020   \n",
       "8568                                         R. Housley    March 2020   \n",
       "8569                                           M. Welzl  1 April 2020   \n",
       "\n",
       "                  Formats  Obsolotes Obsoloted_by  Updates Updated_by  \\\n",
       "0               TXT, HTML        NaN          NaN      NaN        NaN   \n",
       "1          TXT, PDF, HTML        NaN          NaN      NaN        NaN   \n",
       "2               TXT, HTML        NaN      RFC0010      NaN        NaN   \n",
       "3               TXT, HTML        NaN          NaN      NaN        NaN   \n",
       "4               TXT, HTML        NaN          NaN      NaN        NaN   \n",
       "...                   ...        ...          ...      ...        ...   \n",
       "8565  HTML, TXT, PDF, XML        NaN          NaN      NaN        NaN   \n",
       "8566  HTML, TXT, PDF, XML        NaN          NaN  RFC6987        NaN   \n",
       "8567  HTML, TXT, PDF, XML        NaN          NaN      NaN        NaN   \n",
       "8568  HTML, TXT, PDF, XML        NaN          NaN      NaN        NaN   \n",
       "8569  HTML, TXT, PDF, XML        NaN          NaN      NaN        NaN   \n",
       "\n",
       "     Also_FYI             Status               DOI  \n",
       "0         NaN            UNKNOWN  10.17487/RFC0001  \n",
       "1         NaN            UNKNOWN  10.17487/RFC0002  \n",
       "2         NaN            UNKNOWN  10.17487/RFC0003  \n",
       "3         NaN            UNKNOWN  10.17487/RFC0004  \n",
       "4         NaN            UNKNOWN  10.17487/RFC0005  \n",
       "...       ...                ...               ...  \n",
       "8565      NaN      INFORMATIONAL  10.17487/RFC8769  \n",
       "8566      NaN  PROPOSED STANDARD  10.17487/RFC8770  \n",
       "8567      NaN       EXPERIMENTAL  10.17487/RFC8771  \n",
       "8568      NaN       EXPERIMENTAL  10.17487/RFC8773  \n",
       "8569      NaN      INFORMATIONAL  10.17487/RFC8774  \n",
       "\n",
       "[8570 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filepath = '/raid/antoloui/Master-thesis/_data/search/rfc/info.csv'\n",
    "df = pd.read_csv(filepath) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
